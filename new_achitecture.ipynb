{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import levy_stable\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_sample():\n",
    "    # Sample from prior distribution\n",
    "    # For univariate alpha-stable models, sample each parameter from its respective uniform distribution\n",
    "    #np.random.seed(seed)\n",
    "    alpha = uniform.rvs(1.1, 0.9)  # U[1.1, 2]\n",
    "    beta = uniform.rvs(-1, 2)  # U[-1, 1]\n",
    "    gamma = uniform.rvs(0, 300)  # U[0, 300]\n",
    "    delta = uniform.rvs(-300, 600)  # U[-300, 300]\n",
    "    return [alpha, beta, gamma, delta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univ_alpha_stable_sampler(params,size,seed) :\n",
    "    alpha,beta,gamma,delta = params[0],params[1],params[2],params[3]\n",
    "    #print(alpha,beta,gamma,delta)\n",
    "    y_bar = 0\n",
    "    np.random.seed(seed)\n",
    "    w = np.random.standard_exponential(size=size)\n",
    "    u = np.random.uniform(low = -np.pi/2, high = np.pi/2, size = size)\n",
    "    if alpha == 1 :\n",
    "        y_bar = 2/np.pi*((np.pi/2+beta*u)*np.tan(u)-beta*np.log((np.pi/2*w*np.cos(u))/(np.pi/2+beta*u)))\n",
    "        return gamma*y_bar + delta\n",
    "    else :\n",
    "        S = (1+beta**2*np.tan(np.pi*alpha/2)**2)**(1/(2*alpha))\n",
    "        B = 1/alpha*np.arctan(beta*np.tan(np.pi*alpha/2))\n",
    "        #print(S,B)\n",
    "        y_bar = (S*(np.sin(alpha)*(u+B))*(np.cos(u-alpha*(u+B))/w)**((1-alpha)/alpha))/np.cos(u)**(1/alpha)\n",
    "        return gamma*y_bar + delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quantiles(data):\n",
    "    # Compute quantile-based summary statistics\n",
    "    quantiles = np.percentile(data, [5, 25, 50, 75, 95])\n",
    "    v_alpha = (quantiles[4] - quantiles[0]) / (quantiles[3] - quantiles[1])\n",
    "    v_beta = (quantiles[4] + quantiles[0] - 2 * quantiles[2]) / (quantiles[4] - quantiles[0])\n",
    "    v_gamma = (quantiles[3] - quantiles[1]) / quantiles[2]\n",
    "    return v_alpha, v_beta, v_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S(data):\n",
    "    # Compute summary statistics of the data\n",
    "    # This function should return low-dimensional summary statistics S(data)\n",
    "    # For univariate alpha-stable models, use quantile-based estimators along with the mean of the data\n",
    "    v_alpha, v_beta, v_gamma = compute_quantiles(data)\n",
    "    mean_x = np.mean(data)\n",
    "    return np.array([v_alpha, v_beta, v_gamma, mean_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(y, x, covariance = np.diag([0.25,0.25,1,1])):\n",
    "    # Define smoothing kernel using a Gaussian kernel with estimated covariance\n",
    "    return multivariate_normal.pdf(y, mean=x, cov=covariance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_estimate(theta_hat,n_draws = 1000):\n",
    "    x = np.array([univ_alpha_stable_sampler(params = theta_hat, size = 200, seed=None) for _ in range(n_draws)])\n",
    "    sumary_statistics = np.array([S(x_i) for x_i in x])\n",
    "\n",
    "    return np.cov(sumary_statistics, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm2(u) :\n",
    "    return np.sqrt(np.sum(u*u))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K(u, sigma) :\n",
    "    d = sigma.shape[0]\n",
    "    #print(d)\n",
    "    return np.exp(-(u.T@np.linalg.inv(sigma)@u)/2)/(np.sqrt(2*np.pi)**d*np.sqrt(np.linalg.det(sigma)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(theta, weights,N) :\n",
    "    normalized_weights = weigths/np.sum(weights)\n",
    "    theta['t'] = np.random.choice(theta['t-1'], size=N, replace=True, p=normalized_weights)\n",
    "    weights['t'] = np.ones(N)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_M_t(N, theta_prev, weights_prev):\n",
    "    normalized_weights = weights_prev/np.sum(weights_prev)\n",
    "    # Choose a component based on the weights\n",
    "    component = np.random.choice(range(N), p=normalized_weights)\n",
    "    # Generate a sample from the chosen component\n",
    "    sample = np.random.multivariate_normal(mean = theta_prev[component], cov = np.diag([0.25,0.25,1,1]))\n",
    "    #samples[i] = sample\n",
    "    return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_t(N,theta_i,theta_prev, weights_prev) :\n",
    "    densities = np.array([ psi(theta_i, theta_prev[i]) for i in range(N)])\n",
    "    return np.sum(weights_prev*densities)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMC_sampler_v2(arg, T=10,N =1000,n=200,covariance = np.diag([0.25, 0.25, 1, 1]), seed=42) :\n",
    "    #epsilons = [k for k in range(1000,100, -100)]+[k for k in range(100,9, -1)] + [k+0.5 for k in range(9,4,-1)] + [5-k*0.05 for k in range(40)]+[3-0.01*k for k in range(301)]  # Tolerance schedule\n",
    "    epsilons = [3-0.01*k for k in range(301)]\n",
    "    T = len(epsilons)\n",
    "\n",
    "    #y = levy_stable.rvs(1.7, 0.9, loc=10, scale=10, size=200)\n",
    "    ###--------Initialization :\n",
    "    epsilon = epsilons[0]\n",
    "    # 1 - sample theta from the prior : \n",
    "    # theta is a Nx4 matrix containing all the N theta_i\n",
    "    #initial_theta = np.array([prior_sample(seed) for _ in range(N)])\n",
    "    #theta = {\"t\" : initial_theta , \"t-1\" :initial_theta }\n",
    "    # set weights their initial values :\n",
    "    #x = np.array([univ_alpha_stable_sampler(params=theta['t'][i], size=n, seed=seed) for i in range(N)])\n",
    "    #print('x.shape = ',x.shape)\n",
    "    #initial_weights = np.array([K((S(y)-S(x))/epsilon,sigma_hat(theta_hat))/epsilon for theta_hat in theta['t']])\n",
    "    #print(\"weights = \", initial_weights)\n",
    "    #print(\" sum(weights) = \", np.sum(initial_weights))\n",
    "    #weights = {\"t\" : initial_weights, \"t-1\" : initial_weights}\n",
    "    y,x,theta,weights,sigma_hat = arg\n",
    "    t=1\n",
    "    res = []\n",
    "    \n",
    "    print(\"INITIALIZATION IS DONE :)\")\n",
    "    while t<T :\n",
    "        print(\"t = \",t)\n",
    "        epsilon = epsilons[t]\n",
    "        print(\"epsilon = \",epsilon)\n",
    "        accepted = []\n",
    "        rejected = []\n",
    "        theta_maj = theta['t']\n",
    "        weights_maj = weights['t']\n",
    "        i = 0 \n",
    "        while i<N : \n",
    "            print('###########    i = ',i)\n",
    "            # Mutation and correction : \n",
    "            theta['t'][i] = sample_from_M_t(N, theta['t-1'], weights['t-1'])\n",
    "            print(f'theta[\"t\"][{i}]= ', np.round(theta['t'][i],3))\n",
    "            #sigma_hat = cov_estimate(np.array([1.7,0.9,10,10]))\n",
    "            weights['t'][i] = K((S(y)-S(x[i]))/epsilon,sigma_hat)/epsilon/M_t(N,theta['t'][i],theta['t-1'],weights['t-1'])\n",
    "            print('weights[\"t\"] = ', np.round(weights['t'][:5],3))\n",
    "            #theta['t-1'] = theta_maj\n",
    "            #weights['t-1'] = weights_maj\n",
    "            u = np.random.uniform(low=0, high=1, size=1)\n",
    "            c_t = np.quantile(weights['t'], 0.9)\n",
    "            proba = 1-np.minimum(1,weights['t']/c_t)\n",
    "            print(\"c_t = \", c_t)\n",
    "            print(f\"weights['t'][{i}]/c_t = \", weights['t'][i]/c_t)\n",
    "            print(f'proba[{i}] = ', proba[i])\n",
    "            if u<=proba[i] :\n",
    "                print(f\"theta['t'][{i}] = {np.round(theta['t'][i],3)} rejected !\")\n",
    "                continue\n",
    "            else : \n",
    "                print(f\"theta['t'][{i}] = {np.round(theta['t'][i],3)} accepted !\")\n",
    "                weights['t'][i] = weights['t'][i]/proba[i]\n",
    "                i = i+1\n",
    "            \"\"\"\n",
    "            rejected = theta['t'][u<=proba]\n",
    "            accepted = theta['t'][u>proba]\n",
    "            \n",
    "            print(\"accepted = \",accepted)\n",
    "            print(\"acceptance pourcentage = \", len(accepted)*100/N)\n",
    "            print(\"rejected = \" ,rejected)\n",
    "            print(\"rejected pourcentage = \", len(rejected)*100/N)\n",
    "            \"\"\"\n",
    "        t+=1\n",
    "        theta['t-1'],weigths['t-1'] = theta_maj,weights_maj\n",
    "        res.append((theta['t'], weights['t']))\n",
    "        # Resample : \n",
    "        resample(theta,weights,N)\n",
    "        print(\"theta = \", theta[:5])\n",
    "        print(\"weights = \", weights[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(T=10,N =1000,n=200,covariance = np.diag([0.25, 0.25, 1, 1]), seed=42) :\n",
    "    #epsilons = [k for k in range(1000,100, -100)]+[k for k in range(100,9, -1)] + [k+0.5 for k in range(9,4,-1)] + [5-k*0.05 for k in range(40)]+[3-0.01*k for k in range(301)]  # Tolerance schedule\n",
    "    epsilons = [3-0.01*k for k in range(301)]\n",
    "    T = len(epsilons)\n",
    "    y = levy_stable.rvs(1.7, 0.9, loc=10, scale=10, size=200)\n",
    "    ###--------Initialization :\n",
    "    epsilon = epsilons[0]\n",
    "\n",
    "    sigma_hat = cov_estimate(np.array([1.7,0.9,10,10]))\n",
    "    print(\"sigma_hat = \", sigma_hat)\n",
    "    print('det(sigma_hat) = ', np.linalg.det(sigma_hat))\n",
    "    # 1 - sample theta from the prior : \n",
    "    # theta is a Nx4 matrix containing all the N theta_i\n",
    "    initial_theta = np.array([prior_sample() for _ in range(N)])\n",
    "    theta = {\"t\" : initial_theta , \"t-1\" :initial_theta }\n",
    "    print('theta[\"t\"] = ',np.round(theta['t'][:5],4))\n",
    "    # set weights their initial values :\n",
    "    x = np.array([univ_alpha_stable_sampler(params=theta['t'][i], size=n, seed=seed) for i in range(N)])\n",
    "    print('x.shape = ',x.shape)\n",
    "    initial_weights = np.array([K((S(y)-S(x[i]))/epsilon,sigma_hat)/epsilon for i in range(N)])\n",
    "    print(\"weights = \", initial_weights)\n",
    "    print(\" sum(weights) = \", np.sum(initial_weights))\n",
    "    weights = {\"t\" : initial_weights, \"t-1\" : initial_weights}\n",
    "\n",
    "    return y,x,theta,weights,sigma_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMC_sampler_v2(arg=arg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
